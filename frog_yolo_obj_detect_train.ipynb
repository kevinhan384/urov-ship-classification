{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "tNXsY1xeFfXr",
        "outputId": "3060b7a0-980c-41e7-8ae9-4fa75107476b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT6EiFxdrMji"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "train_images_folder = \"/content/drive/MyDrive/Colab Notebooks/FrogImages/Train/images\"\n",
        "print(len(os.listdir(train_images_folder)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQc1vVpOEr1j"
      },
      "outputs": [],
      "source": [
        "#Install ultralytics library for YOLO\n",
        "!pip install --upgrade ultralytics -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unrdPNybEr1k"
      },
      "outputs": [],
      "source": [
        "#Check for success of ultralytics library installation\n",
        "import ultralytics\n",
        "print(ultralytics.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF3JabeWEr1k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import random\n",
        "import yaml\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwxVtclEEr1l"
      },
      "outputs": [],
      "source": [
        "\"\"\"Create CFG class to configure training\"\"\"\n",
        "\n",
        "class CFG:\n",
        "    DEBUG = False\n",
        "    FRACTION = 0.05 if DEBUG else 1.0\n",
        "    SEED = 88\n",
        "\n",
        "    #Classification class info\n",
        "    CLASSES = [\"Frog\"]\n",
        "    NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "    #Training\n",
        "    EPOCHS = 3 if DEBUG else 50\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    BASE_MODEL = \"yolov8x\"\n",
        "    BASE_MODEL_WEIGHTS = f'{BASE_MODEL}.pt'\n",
        "    EXP_NAME = f\"ppe_css_{EPOCHS}_epochs\"\n",
        "\n",
        "    OPTIMIZER = \"Adam\"\n",
        "    LR = 1e-3\n",
        "    LR_FACTOR = 0.01\n",
        "    WEIGHT_DECAY = 5e-4\n",
        "    DROPOUT = 0.3\n",
        "    PATIENCE = 15\n",
        "    PROFILE = False\n",
        "    LABEL_SMOOTHING = 0.0\n",
        "\n",
        "    #paths\n",
        "    CUSTOM_DATASET_DIR =  \"/content/drive/MyDrive/Colab Notebooks/FrogImages\"\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/FrogImages\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEO9Z9A6Er1l"
      },
      "outputs": [],
      "source": [
        "#Create YAML file for training\n",
        "dict_file = {\n",
        "    'train': os.path.join(CFG.CUSTOM_DATASET_DIR, 'Train'),\n",
        "    'val': os.path.join(CFG.CUSTOM_DATASET_DIR, 'Val'),\n",
        "    'nc': CFG.NUM_CLASSES,\n",
        "    'names': CFG.CLASSES\n",
        "}\n",
        "\n",
        "print(os.path.join(CFG.OUTPUT_DIR, \"data.yaml\"))\n",
        "with open(os.path.join(CFG.OUTPUT_DIR, \"data.yaml\"), \"w+\") as file:\n",
        "    yaml.dump(dict_file, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NDMRGGjEr1m"
      },
      "outputs": [],
      "source": [
        "#Read YAML file\n",
        "def read_yaml(file_path=CFG.CUSTOM_DATASET_DIR):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        try:\n",
        "            data = yaml.safe_load(file)\n",
        "            return data\n",
        "        except yaml.YAMLError as e:\n",
        "            print(\"Error reading YAML:\", e)\n",
        "            return None\n",
        "\n",
        "def print_yaml(data):\n",
        "    formatted_yaml = yaml.dump(data, default_style=False)\n",
        "    print(formatted_yaml)\n",
        "\n",
        "yaml_path = os.path.join(CFG.OUTPUT_DIR, \"data.yaml\")\n",
        "yaml_data = read_yaml(yaml_path)\n",
        "if yaml_data:\n",
        "    print_yaml(yaml_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pICxiOfTEr1m"
      },
      "outputs": [],
      "source": [
        "def display_image(image, print_info = True, hide_axis = False):\n",
        "    if isinstance(image, str):  # Check if it's a file path\n",
        "        img = Image.open(image)\n",
        "        plt.imshow(img)\n",
        "    elif isinstance(image, np.ndarray):  # Check if it's a NumPy array\n",
        "        image = image[..., ::-1]  # BGR to RGB\n",
        "        img = Image.fromarray(image)\n",
        "        plt.imshow(img)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported image format\")\n",
        "\n",
        "    if print_info:\n",
        "        print('Type: ', type(img), '\\n')\n",
        "        print('Shape: ', np.array(img).shape, '\\n')\n",
        "\n",
        "    if hide_axis:\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KObsMTS7Er1m"
      },
      "outputs": [],
      "source": [
        "example_image_path = '/content/drive/MyDrive/Colab Notebooks/FrogImages/Train/images/frogs1.jpg'\n",
        "display_image(example_image_path, print_info = True, hide_axis = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onlS1v21Er1n"
      },
      "outputs": [],
      "source": [
        "def plot_random_images_from_folder(folder_path, num_images=20, seed=CFG.SEED):\n",
        "\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Get a list of image files in the folder\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg', '.gif'))]\n",
        "\n",
        "    # Ensure that we have at least num_images files to choose from\n",
        "    if len(image_files) < num_images:\n",
        "        raise ValueError(\"Not enough images in the folder\")\n",
        "\n",
        "    # Randomly select num_images image files\n",
        "    selected_files = random.sample(image_files, num_images)\n",
        "\n",
        "    # Create a subplot grid\n",
        "    num_cols = 5\n",
        "    num_rows = (num_images + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
        "\n",
        "    for i, file_name in enumerate(selected_files):\n",
        "        # Open and display the image using PIL\n",
        "        img = Image.open(os.path.join(folder_path, file_name))\n",
        "\n",
        "        if num_rows == 1:\n",
        "            ax = axes[i % num_cols]\n",
        "        else:\n",
        "            ax = axes[i // num_cols, i % num_cols]\n",
        "\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        # ax.set_title(file_name)\n",
        "\n",
        "    # Remove empty subplots\n",
        "    for i in range(num_images, num_rows * num_cols):\n",
        "        if num_rows == 1:\n",
        "            fig.delaxes(axes[i % num_cols])\n",
        "        else:\n",
        "            fig.delaxes(axes[i // num_cols, i % num_cols])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqLmsn-1Er1n"
      },
      "outputs": [],
      "source": [
        "folder_path = CFG.CUSTOM_DATASET_DIR + '/Train/images'\n",
        "plot_random_images_from_folder(folder_path, num_images=20, seed=CFG.SEED)\n",
        "# plot_random_images_from_folder(folder_path, num_images=20, seed=54)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25XNYBN7Er1n"
      },
      "outputs": [],
      "source": [
        "def get_image_properties(image_path):\n",
        "    # Read the image file\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Check if the image file is read successfully\n",
        "    if img is None:\n",
        "        raise ValueError(\"Could not read image file\")\n",
        "\n",
        "    # Get image properties\n",
        "    properties = {\n",
        "        \"width\": img.shape[1],\n",
        "        \"height\": img.shape[0],\n",
        "        \"channels\": img.shape[2] if len(img.shape) == 3 else 1,\n",
        "        \"dtype\": img.dtype,\n",
        "    }\n",
        "\n",
        "    return properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz53ZjRbEr1n"
      },
      "outputs": [],
      "source": [
        "img_properties = get_image_properties(example_image_path)\n",
        "img_properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umpA-lFhEr1o"
      },
      "outputs": [],
      "source": [
        "for mode in ['train', 'valid']:\n",
        "    print(f'\\nImage sizes in {mode} set:')\n",
        "\n",
        "    img_size = 0\n",
        "    for file in glob.glob(os.path.join(CFG.CUSTOM_DATASET_DIR, mode, '*')):\n",
        "        if file.endswith(\".jpg\"):\n",
        "          image = Image.open(file)\n",
        "          if image.size != img_size:\n",
        "              #print(f'{image.size}')\n",
        "              img_size = image.size\n",
        "              #print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_chfdD-8Er1o"
      },
      "outputs": [],
      "source": [
        "#Check pretrained model's accuracy with dataset\n",
        "model = YOLO(CFG.BASE_MODEL_WEIGHTS)\n",
        "\n",
        "results = model.predict(\n",
        "    source=example_image_path,\n",
        "    classes=[0],\n",
        "    conf=0.3,\n",
        "    device=0, #Only works when GPU is on\n",
        "    imgsz=(img_properties[\"height\"], img_properties[\"width\"]),\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    save_conf=True,\n",
        "    exist_ok=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MBizyTFEr1o"
      },
      "outputs": [],
      "source": [
        "### check predictions with base model\n",
        "example_image_inference_output = example_image_path.split('/')[-1]\n",
        "display_image(f'/content/runs/detect/predict/{example_image_inference_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB0Nn7O_Er1o"
      },
      "outputs": [],
      "source": [
        "#Output basic training configuration\n",
        "print('Model: ', CFG.BASE_MODEL_WEIGHTS)\n",
        "print('Epochs: ', CFG.EPOCHS)\n",
        "print('Batch: ', CFG.BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htCWBcaBEr1o"
      },
      "outputs": [],
      "source": [
        "### Load pre-trained YOLO model\n",
        "model = YOLO(CFG.BASE_MODEL_WEIGHTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xijw3dPfEr1o"
      },
      "outputs": [],
      "source": [
        "### train\n",
        "model.train(\n",
        "    data = os.path.join(CFG.OUTPUT_DIR, 'data.yaml'),\n",
        "\n",
        "    task = 'detect',\n",
        "\n",
        "    imgsz = (img_properties['height'], img_properties['width']),\n",
        "\n",
        "    epochs = CFG.EPOCHS,\n",
        "    batch = CFG.BATCH_SIZE,\n",
        "    optimizer = CFG.OPTIMIZER,\n",
        "    lr0 = CFG.LR,\n",
        "    lrf = CFG.LR_FACTOR,\n",
        "    weight_decay = CFG.WEIGHT_DECAY,\n",
        "    dropout = CFG.DROPOUT,\n",
        "    fraction = CFG.FRACTION,\n",
        "    patience = CFG.PATIENCE,\n",
        "    profile = CFG.PROFILE,\n",
        "    label_smoothing = CFG.LABEL_SMOOTHING,\n",
        "\n",
        "    name = f'{CFG.BASE_MODEL}_{CFG.EXP_NAME}',\n",
        "    seed = CFG.SEED,\n",
        "\n",
        "    val = True,\n",
        "    amp = True,\n",
        "    exist_ok = True,\n",
        "    resume = False,\n",
        "    device = 0,\n",
        "    verbose = False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr4je2hpblo1"
      },
      "outputs": [],
      "source": [
        "#Test previous model without actually training\n",
        "WEIGHTS = '/content/drive/MyDrive/Colab Notebooks/best frogs (4).pt'\n",
        "model =  YOLO(WEIGHTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjrNVvWdOdFA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "results_image_path = \"/content/drive/MyDrive/Colab Notebooks/FrogImages/Test\"\n",
        "results_images = [file for file in os.listdir(results_image_path) if file.endswith(\".jpg\")]\n",
        "#example_image_path = os.path.join(results_image_path, random.choice(results_images))\n",
        "#example_image_path = os.path.join(results_image_path, \"waftgreentreefrogamplexis-bg.jpg\")\n",
        "for img in results_images:\n",
        "  example_image_path = os.path.join(results_image_path, img)\n",
        "  results = model.predict(\n",
        "      source=example_image_path,\n",
        "      classes=[0],\n",
        "      conf=0.5,\n",
        "      device='cpu', #Only works when GPU is on\n",
        "      imgsz=(img_properties[\"height\"], img_properties[\"width\"]),\n",
        "      save=True,\n",
        "      save_txt=True,\n",
        "      save_conf=True,\n",
        "      exist_ok=True\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPaPP9moXk8x"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f'runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/results.csv')\n",
        "df = df.rename(columns=lambda x: x.replace(\" \", \"\"))\n",
        "df.to_csv(f'{CFG.OUTPUT_DIR}training_log_df.csv', index=False)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hklI-od0XmID"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15), sharex=True)\n",
        "\n",
        "### Training and Validation Box Loss\n",
        "ax1.set_title('Box Loss')\n",
        "ax1.plot(df['epoch'], df['train/box_loss'], label='Training box_loss', marker='o', linestyle='-')\n",
        "ax1.plot(df['epoch'], df['val/box_loss'], label='Validation box_loss', marker='o', linestyle='-')\n",
        "ax1.set_ylabel('Box Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "### Training and Validation cls_loss\n",
        "ax2.set_title('Cls Loss')\n",
        "ax2.plot(df['epoch'], df['train/cls_loss'], label='Training cls_loss', marker='o', linestyle='-')\n",
        "\n",
        "ax2.plot(df['epoch'], df['val/cls_loss'], label='Validation cls_loss', marker='o', linestyle='-')\n",
        "ax2.set_ylabel('cls_loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "### Training and Validation dfl_loss\n",
        "ax3.set_title('DFL Loss')\n",
        "ax3.plot(df['epoch'], df['train/dfl_loss'], label='Training dfl_loss', marker='o', linestyle='-')\n",
        "ax3.plot(df['epoch'], df['val/dfl_loss'], label='Validation dfl_loss', marker='o', linestyle='-')\n",
        "ax3.set_xlabel('Epochs')\n",
        "ax3.set_ylabel('dfl_loss')\n",
        "ax3.legend()\n",
        "ax3.grid(True)\n",
        "\n",
        "plt.suptitle('Training Metrics vs. Epochs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ859usTXuoU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(f'runs/detect/{CFG.BASE_MODEL}_{CFG.EXP_NAME}/results.csv')\n",
        "df = df.rename(columns=lambda x: x.replace(\" \", \"\"))\n",
        "df.to_csv(f'{CFG.OUTPUT_DIR}training_log_df.csv', index=False)\n",
        "\n",
        "# Extract metrics for plotting\n",
        "epochs = df['epoch']\n",
        "train_mAP50 = df['metrics/mAP50(B)']\n",
        "val_mAP50 = df['metrics/mAP50(B)']\n",
        "train_mAP95 = df['metrics/mAP95(B)']\n",
        "val_mAP95 = df['metrics/mAP95(B)']\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, train_mAP50, label='Train mAP50')\n",
        "plt.plot(epochs, val_mAP50, label='Validation mAP50')\n",
        "plt.plot(epochs, train_mAP95, label='Train mAP95')\n",
        "plt.plot(epochs, val_mAP95, label='Validation mAP95')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('mAP')\n",
        "plt.title('mAP50 and mAP95 over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Print the final mAP values\n",
        "final_mAP50 = val_mAP50.iloc[-1]\n",
        "final_mAP95 = val_mAP95.iloc[-1]\n",
        "print(f'Final Validation mAP50: {final_mAP50:.4f}')\n",
        "print(f'Final Validation mAP95: {final_mAP95:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 1144726,
          "sourceId": 1919543,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 2919095,
          "sourceId": 5048288,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30635,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}